{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Hyperparameter Optimization Project\n",
    "\n",
    "## Fall 2021 - Team 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you try to optimize hyperparameters ``C`` and ``solver`` of the classifier by using optuna.\n",
    "When you introduce optuna naively, you define an ``objective`` function\n",
    "such that it takes ``trial`` and calls ``suggest_*`` methods of ``trial`` to sample the hyperparameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a Python class for project\n",
    "\n",
    "class Tune:\n",
    "    search_space_C = None\n",
    "    search_space_solver = None\n",
    "    study = None\n",
    "    trial = None\n",
    "    objective = None\n",
    "    performance = None\n",
    "    C = None\n",
    "    solver = None\n",
    "    \n",
    "    def create_study(self, C, solver):\n",
    "        self.search_space_C = C\n",
    "        self.search_space_solver = solver\n",
    "        \n",
    "        # The function needs to be more generalizbale, later change required\n",
    "        self.study = optuna.create_study(direction=\"maximize\")\n",
    "        self.trial = self.study.ask()\n",
    "        self.C = self.trial.suggest_loguniform(\"C\", self.search_space_C[0], self.search_space_C[1])\n",
    "        self.solver = self.trial.suggest_categorical(\"solver\", set(self.search_space_solver))\n",
    "        print(\"Hyperparameter:\", self.C)\n",
    "        print(\"Solver:\", self.solver)\n",
    "    \n",
    "    def update_study(self):\n",
    "        self.get_performance()\n",
    "        self.trial = self.study.ask()\n",
    "        self.C = self.trial.suggest_loguniform(\"C\", self.search_space_C[0], self.search_space_C[1])\n",
    "        self.solver = self.trial.suggest_categorical(\"solver\", set(self.search_space_solver))\n",
    "        self.study.tell(self.trial, self.performance)\n",
    "        # insert flask call to store current performance and values\n",
    "        return self.C, self.solver\n",
    "    \n",
    "    def update_study_multiple(self, n):\n",
    "        for _ in n:\n",
    "            self.update_study()\n",
    "        # flask call, retrive best study\n",
    "    \n",
    "    def set_objective(self, objective):\n",
    "        self.objective = objective\n",
    "        print(\"Objective has been set.\")\n",
    "    \n",
    "    def get_performance(self):\n",
    "        self.performance = self.objective(self.C, self.solver)\n",
    "        print(\"Current Model Performance:\", self.performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defines data and split\n",
    "\n",
    "X, y = make_classification(n_features=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user defines objective function\n",
    "\n",
    "def objective(C, solver):\n",
    "    clf = LogisticRegression(C=C, solver=solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = Tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-02 18:16:06,535]\u001b[0m A new study created in memory with name: no-name-82c6938a-743e-452d-8cc3-1b1b27850905\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperparameter: 3.091858591608382e-06\n",
      "Solver: lbfgs\n"
     ]
    }
   ],
   "source": [
    "tune.create_study([1e-7, 10.0], [\"lbfgs\", \"saga\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Objective has been set.\n"
     ]
    }
   ],
   "source": [
    "tune.set_objective(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Model Performance: 0.4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.00015550332306482872, 'lbfgs')"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.update_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
