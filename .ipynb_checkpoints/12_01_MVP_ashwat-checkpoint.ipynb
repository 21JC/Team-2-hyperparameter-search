{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Ask-and-Tell Interface\n",
    "\n",
    "Optuna has an `Ask-and-Tell` interface, which provides a more flexible interface for hyperparameter optimization.\n",
    "This tutorial explains three use-cases when the ask-and-tell interface is beneficial:\n",
    "\n",
    "- `Apply-optuna-to-an-existing-optimization-problem-with-minimum-modifications`\n",
    "- `Define-and-Run`\n",
    "- `Batch-Optimization`\n",
    "\n",
    "\n",
    "## Apply Optuna to an existing optimization problem with minimum modifications\n",
    "\n",
    "Let's consider the traditional supervised classification problem; you aim to maximize the validation accuracy.\n",
    "To do so, you train `LogisticRegression` as a simple model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you try to optimize hyperparameters ``C`` and ``solver`` of the classifier by using optuna.\n",
    "When you introduce optuna naively, you define an ``objective`` function\n",
    "such that it takes ``trial`` and calls ``suggest_*`` methods of ``trial`` to sample the hyperparameters:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import optuna\n",
    "\n",
    "X, y = make_classification(n_features=10)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "C = 0.01\n",
    "clf = LogisticRegression(C=C)\n",
    "clf.fit(X_train, y_train)\n",
    "val_accuracy = clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# building a Python class for project\n",
    "\n",
    "class Tune:\n",
    "    search_space_C = None\n",
    "    search_space_solver = None\n",
    "    study = None\n",
    "    trial = None\n",
    "    objective = None\n",
    "    performance = None\n",
    "    \n",
    "    def create_study(self, C, solver):\n",
    "        self.search_space_C = C\n",
    "        self.search_space_solver = solver\n",
    "        \n",
    "        # The function needs to be more generalizbale, later change required\n",
    "        self.study = optuna.create_study(direction=\"maximize\")\n",
    "        self.trial = self.study.ask()\n",
    "        C = self.trial.suggest_loguniform(\"C\", self.search_space_C[0], self.search_space_C[1])\n",
    "        solver = self.trial.suggest_categorical(\"solver\", set(self.search_space_solver))\n",
    "        return C, solver\n",
    "    \n",
    "    def update_study(self):\n",
    "        self.get_performance()\n",
    "        self.trial = self.study.ask()\n",
    "        C = self.trial.suggest_loguniform(\"C\", self.search_space_C[0], self.search_space_C[1])\n",
    "        solver = self.trial.suggest_categorical(\"solver\", set(self.search_space_solver))\n",
    "        self.study.tell(self.trial, self.performance)\n",
    "        return C, solver\n",
    "    \n",
    "    def set_objective(self, objective):\n",
    "        self.objective = objective\n",
    "    \n",
    "    def get_performance(self):\n",
    "        self.performance = self.objective(self.search_space_C, self.search_space_solver)\n",
    "        return self.performance\n",
    "    \n",
    "    \n",
    "#     # Within API\n",
    "#     def update_study(performance, study,trial,search_space_C,search_space_solver ):\n",
    "#         trial = study.ask()\n",
    "#         C = trial.suggest_loguniform(\"C\", search_space_C[0], search_space_C[1])\n",
    "#         solver = trial.suggest_categorical(\"solver\", set(search_space_solver))\n",
    "#         study.tell(trial, performance)\n",
    "#         return C, solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(C, solver):\n",
    "    X, y = make_classification(n_features=10)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "#     C = trial.suggest_loguniform(\"C\", 1e-7, 10.0)\n",
    "#     solver = trial.suggest_categorical(\"solver\", (\"lbfgs\", \"saga\"))\n",
    "\n",
    "    clf = LogisticRegression(C=C, solver=solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    return val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune = Tune()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-12-02 16:38:24,245]\u001b[0m A new study created in memory with name: no-name-93d6eabd-064f-48f8-89c9-ecbb6c29a509\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8007140960015626, 'lbfgs')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.create_study([1e-7, 10.0],[\"lbfgs\", \"saga\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1e-07, 10.0], {'lbfgs', 'saga'})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddtune.search_space_C, tune.search_space_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune.set_objective(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1e-07, 10.0], {'lbfgs', 'saga'})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune.search_space_C, tune.search_space_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got {'saga', 'lbfgs'}.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-2e4b1da20228>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-4cadfaf295e2>\u001b[0m in \u001b[0;36mget_performance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-3d6cf3e34d4f>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(C, solver)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \"\"\"\n\u001b[0;32m-> 1304\u001b[0;31m         \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[0;34m(solver, penalty, dual)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mall_solvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saga'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_solvers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         raise ValueError(\"Logistic Regression supports only solvers in %s, got\"\n\u001b[0m\u001b[1;32m    434\u001b[0m                          \" %s.\" % (all_solvers, solver))\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got {'saga', 'lbfgs'}."
     ]
    }
   ],
   "source": [
    "tune.get_performance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "tune.search_space_C, tune.search_space_solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'saga'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-c785038315f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtune\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-57f2257d7a7e>\u001b[0m in \u001b[0;36mupdate_study\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest_loguniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-57f2257d7a7e>\u001b[0m in \u001b[0;36mget_performance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space_C\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch_space_solver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-3d6cf3e34d4f>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(C, solver)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mval_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1302\u001b[0m         \u001b[0mThe\u001b[0m \u001b[0mSAGA\u001b[0m \u001b[0msolver\u001b[0m \u001b[0msupports\u001b[0m \u001b[0mboth\u001b[0m \u001b[0mfloat64\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfloat32\u001b[0m \u001b[0mbit\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \"\"\"\n\u001b[0;32m-> 1304\u001b[0;31m         \u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_solver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_check_solver\u001b[0;34m(solver, penalty, dual)\u001b[0m\n\u001b[1;32m    431\u001b[0m     \u001b[0mall_solvers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lbfgs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sag'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saga'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_solvers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m         raise ValueError(\"Logistic Regression supports only solvers in %s, got\"\n\u001b[0m\u001b[1;32m    434\u001b[0m                          \" %s.\" % (all_solvers, solver))\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Logistic Regression supports only solvers in ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'], got ['lbfgs', 'saga']."
     ]
    }
   ],
   "source": [
    "tune.update_study()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within API\n",
    "\n",
    "def create_study(C, solver): # these two are search space \n",
    "    # The function needs to be more generalizbale, later change required\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    trial = study.ask()\n",
    "    C = trial.suggest_loguniform(\"C\", C[0], C[1])\n",
    "    solver = trial.suggest_categorical(\"solver\", set(solver))\n",
    "    return C, solver, study,trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# needs Generalize \n",
    "C, solver, study, trial = create_study([1e-7, 10.0],[\"lbfgs\", \"saga\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User's code\n",
    "performance = objective(C,solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Within API\n",
    "def update_study(performance, study,trial,search_space_C,search_space_solver ):\n",
    "    trial = study.ask()\n",
    "    C = trial.suggest_loguniform(\"C\", search_space_C[0], search_space_C[1])\n",
    "    solver = trial.suggest_categorical(\"solver\", set(search_space_solver))\n",
    "    study.tell(trial, performance)\n",
    "    return C, solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User's code\n",
    "new_C, new_solver = update_study(performance, study,trial,search_space_C,search_space_solver)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. explanation docu (Jiayang)\n",
    "2. Expand to XGBoost (add input of XBoost algo and hyper params), generalize search_space (dict) (Jiayang, Deepak, Ash, Yuahan)\n",
    "3. wrapping up for simple use, reduce amount of data user need to input (Ashwat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface is not flexible enough.\n",
    "For example, if ``objective`` requires additional arguments other than ``trial``,\n",
    "you need to define a class as in\n",
    "`How to define objective functions that have own arguments? <../../faq.html#how-to-define-objective-functions-that-have-own-arguments>`_.\n",
    "The ask-and-tell interface provides a more flexible syntax to optimize hyperparameters.\n",
    "The following example is equivalent to the previous code block.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "\n",
    "n_trials = 10\n",
    "for _ in range(n_trials):\n",
    "    trial = study.ask()  # `trial` is a `Trial` and not a `FrozenTrial`.\n",
    "\n",
    "    C = trial.suggest_loguniform(\"C\", 1e-7, 10.0)\n",
    "    solver = trial.suggest_categorical(\"solver\", (\"lbfgs\", \"saga\"))\n",
    "\n",
    "    clf = LogisticRegression(C=C, solver=solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    study.tell(trial, val_accuracy)  # tell the pair of trial and objective value\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.suggest_loguniform(\"C\", 1e-7, 10.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main difference is to use two methods: :func:`optuna.study.Study.ask`\n",
    "and :func:`optuna.study.Study.tell`.\n",
    ":func:`optuna.study.Study.ask` creates a trial that can sample hyperparameters, and\n",
    ":func:`optuna.study.Study.tell` finishes the trial by passing ``trial`` and an objective value.\n",
    "You can apply Optuna's hyperparameter optimization to your original code\n",
    "without an ``objective`` function.\n",
    "\n",
    "If you want to make your optimization faster with a pruner, you need to explicitly pass the state of trial\n",
    "to the argument of :func:`optuna.study.Study.tell` method as follows:\n",
    "\n",
    ".. code-block:: python\n",
    "\n",
    "   import numpy as np\n",
    "   from sklearn.datasets import load_iris\n",
    "   from sklearn.linear_model import SGDClassifier\n",
    "   from sklearn.model_selection import train_test_split\n",
    "\n",
    "   import optuna\n",
    "\n",
    "\n",
    "   X, y = load_iris(return_X_y=True)\n",
    "   X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "   classes = np.unique(y)\n",
    "   n_train_iter = 100\n",
    "\n",
    "   # define study with hyperband pruner.\n",
    "   study = optuna.create_study(\n",
    "       direction=\"maximize\",\n",
    "       pruner=optuna.pruners.HyperbandPruner(\n",
    "           min_resource=1, max_resource=n_train_iter, reduction_factor=3\n",
    "       ),\n",
    "   )\n",
    "\n",
    "   for _ in range(20):\n",
    "       trial = study.ask()\n",
    "\n",
    "       alpha = trial.suggest_uniform(\"alpha\", 0.0, 1.0)\n",
    "\n",
    "       clf = SGDClassifier(alpha=alpha)\n",
    "       pruned_trial = False\n",
    "\n",
    "       for step in range(n_train_iter):\n",
    "           clf.partial_fit(X_train, y_train, classes=classes)\n",
    "\n",
    "           intermediate_value = clf.score(X_valid, y_valid)\n",
    "           trial.report(intermediate_value, step)\n",
    "\n",
    "           if trial.should_prune():\n",
    "               pruned_trial = True\n",
    "               break\n",
    "\n",
    "       if pruned_trial:\n",
    "           study.tell(trial, state=optuna.trial.TrialState.PRUNED)  # tell the pruned state\n",
    "       else:\n",
    "           score = clf.score(X_valid, y_valid)\n",
    "           study.tell(trial, score)  # tell objective value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><h4>Note</h4><p>:func:`optuna.study.Study.tell` method can take a trial number rather than the trial object.\n",
    "    ``study.tell(trial.number, y)`` is equivalent to ``study.tell(trial, y)``.</p></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Define-and-Run\n",
    "The ask-and-tell interface supports both `define-by-run` and `define-and-run` APIs.\n",
    "This section shows the example of the `define-and-run` API\n",
    "in addition to the define-by-run example above.\n",
    "\n",
    "Define distributions for the hyperparameters before calling the\n",
    ":func:`optuna.study.Study.ask` method for define-and-run API.\n",
    "For example,\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distributions = {\n",
    "    \"C\": optuna.distributions.LogUniformDistribution(1e-7, 10.0),\n",
    "    \"solver\": optuna.distributions.CategoricalDistribution((\"lbfgs\", \"saga\")),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass ``distributions`` to :func:`optuna.study.Study.ask` method at each call.\n",
    "The retuned ``trial`` contains the suggested hyperparameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "n_trials = 10\n",
    "for _ in range(n_trials):\n",
    "    trial = study.ask(distributions)  # pass the pre-defined distributions.\n",
    "\n",
    "    # two hyperparameters are already sampled from the pre-defined distributions\n",
    "    C = trial.params[\"C\"]\n",
    "    solver = trial.params[\"solver\"]\n",
    "\n",
    "    clf = LogisticRegression(C=C, solver=solver)\n",
    "    clf.fit(X_train, y_train)\n",
    "    val_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "    study.tell(trial, val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Batch Optimization\n",
    "The ask-and-tell interface enables us to optimize a batched objective for faster optimization.\n",
    "For example, parallelizable evaluation, operation over vectors, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following objective takes batched hyperparameters ``xs`` and ``ys`` instead of a single\n",
    "pair of hyperparameters ``x`` and ``y`` and calculates the objective over the full vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batched_objective(xs: np.ndarray, ys: np.ndarray):\n",
    "    return xs ** 2 + ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, the number of pairs of hyperparameters in a batch is $10$,\n",
    "and ``batched_objective`` is evaluated three times.\n",
    "Thus, the number of trials is $30$.\n",
    "Note that you need to store either ``trial_ids`` or ``trial`` to call\n",
    ":func:`optuna.study.Study.tell` method after the batched evaluations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "study = optuna.create_study(sampler=optuna.samplers.CmaEsSampler())\n",
    "\n",
    "for _ in range(3):\n",
    "\n",
    "    # create batch\n",
    "    trial_ids = []\n",
    "    x_batch = []\n",
    "    y_batch = []\n",
    "    for _ in range(batch_size):\n",
    "        trial = study.ask()\n",
    "        trial_ids.append(trial.number)\n",
    "        x_batch.append(trial.suggest_float(\"x\", -10, 10))\n",
    "        y_batch.append(trial.suggest_float(\"y\", -10, 10))\n",
    "\n",
    "    # evaluate batched objective\n",
    "    x_batch = np.array(x_batch)\n",
    "    y_batch = np.array(y_batch)\n",
    "    objectives = batched_objective(x_batch, y_batch)\n",
    "\n",
    "    # finish all trials in the batch\n",
    "    for trial_id, objective in zip(trial_ids, objectives):\n",
    "        study.tell(trial_id, objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
